{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction & Project Context ##\n",
    "In finance, options are contracts that give the buyer the right, not the obligation, to buy or sell an underlying asset at a strike price on or before the expiration date. Among many, the two most common styles of option contracts are European and American. For European-style options, the contract can only be exercised at expiration, so the Black-Scholes PDE can be applied to find a closed-form solution for the price of the option. However, American-style options can be exercised anytime before expiration, which introduces an early exercise boundary. For this reason, no straightforward PDE can be solved to find a formula for the price of the option. \n",
    "\n",
    "There are several techniques for attempting to price American options, but for this project, I will be focusing on the widely used Monte-Carlo method called the **Longstaff-Schwartz algorithm**. As machine learning models become more advanced in their predictive power, I will be exploring how different ML models can be used to perform the regression within the LS algorithm for pricing American options.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Longstaff-Schwartz algorithm works ##\n",
    "\n",
    "The LS algorithm has several parameters regarding the initial behavior of the stock and conditions of the option contract:\n",
    "\n",
    "- $S_0 = \\text{Intial stock price}$\n",
    "- $r = \\text{Risk-Free interest rate}$\n",
    "- $\\sigma = \\text{Volatility}$\n",
    "- $T = \\text{Time to expiration}$\n",
    "- $K = \\text{Strike price}$\n",
    "- $n_{trials} = \\text{number of simulated paths}$\n",
    "- $n_{timesteps} = \\text{number of timesteps per path}$\n",
    "\n",
    "This algorithm uses Monte Carlo simulations to generate different potential paths that the underlying asset may go through. It leverages a backward recursive approach and regression to estimate the expected value of the option. The expected value is compared to the current exercise value to find the optimal payoff at each timestep. The average of all the simulated option prices is taken to determine the final price of the option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def longstaff_schwartz(S0, r, sigma, T, K, n_trials, n_timesteps, option_type, ml_model):\n",
    "    \"\"\"\n",
    "    Core Longstaff-Schwartz implementation with ML models\n",
    "    \"\"\"\n",
    "    # Monte-Carlo simulated paths\n",
    "    S = np.zeros((n_trials, n_timesteps))\n",
    "    S[:,0] = S0\n",
    "    rng = np.random.default_rng(42)\n",
    "    dW = rng.normal(0, 1, (n_trials, n_timesteps))\n",
    "    dt = T / n_timesteps\n",
    "    for t in range(1,n_timesteps):\n",
    "        S_t = S[:,t-1] \n",
    "        S[:,t] = S_t + r*S_t*dt + sigma*S_t*dW[:,t-1] \n",
    "\n",
    "    \n",
    "    ST = S[:,n_timesteps-1]\n",
    "    payoffs = np.zeros((n_trials, n_timesteps))\n",
    "\n",
    "    # Calculate terminal option prices\n",
    "    if option_type == 'call':\n",
    "        payoffs[:,n_timesteps-1] = np.maximum(ST - K, 0)\n",
    "    elif option_type == 'put':\n",
    "        payoffs[:,n_timesteps-1] = np.maximum(K - ST, 0)\n",
    "\n",
    "    # Use backward induction to find final option price \n",
    "    for t in range(n_timesteps-2,-1,-1):\n",
    "        # Determine which paths are in-the-money and out-of-the-money\n",
    "        if option_type == 'call':\n",
    "            itm_indices = np.where(S[:,t] > K)\n",
    "            otm_indices = np.where(S[:,t] <= K)\n",
    "        elif option_type == 'put':\n",
    "            itm_indices = np.where(S[:,t] < K)\n",
    "            otm_indices = np.where(S[:,t] >= K)\n",
    "        # If no paths are in-the-money, do not exercise any option\n",
    "        if len(itm_indices[0]) == 0:\n",
    "            payoffs[:, t] = payoffs[:, t+1] * np.exp(-r*dt)\n",
    "            continue\n",
    "        X = S[itm_indices, t].reshape(-1, 1) # Current stock prices for in-the-money paths\n",
    "        y = payoffs[itm_indices,t+1] * np.exp(-r*dt) # Discounted expected values of the option at the next timestep\n",
    "        # Choose ML model\n",
    "        match ml_model:\n",
    "            case 'poly':\n",
    "                model = make_pipeline(\n",
    "                    PolynomialFeatures(degree=3),\n",
    "                    LinearRegression(fit_intercept=False)\n",
    "                )\n",
    "                model.fit(X, y.ravel())\n",
    "            case 'random forest':\n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(X, y.ravel())\n",
    "            case 'xgboost':\n",
    "                model = xgb.XGBRegressor()\n",
    "                model.fit(X, y)\n",
    "            case 'mlp':\n",
    "                model = MLPRegressor()\n",
    "                model.fit(X, y.ravel())\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown model type: {ml_model}\")\n",
    "            \n",
    "        future_val = model.predict(X).flatten() # Predicted discounted expected value\n",
    "        # Calculate current exercise price\n",
    "        if option_type == 'call':\n",
    "            current_val = np.maximum(S[itm_indices, t] - K, 0).flatten()\n",
    "        elif option_type == 'put':\n",
    "            current_val = np.maximum(K - S[itm_indices, t], 0).flatten()\n",
    "\n",
    "        itm = itm_indices[0]  \n",
    "        # Determines optimal time to exercise the option\n",
    "        should_exercise = current_val > future_val\n",
    "        # Sets payoffs accordingly\n",
    "        payoffs[itm[should_exercise], t] = current_val[should_exercise]\n",
    "        payoffs[itm[~should_exercise], t] = payoffs[itm[~should_exercise], t+1] * np.exp(-r*dt)\n",
    "        payoffs[otm_indices, t] = payoffs[otm_indices, t+1] * np.exp(-r*dt)\n",
    "\n",
    "\n",
    "    price = np.mean(payoffs[:,0]) # average of all option prices\n",
    "\n",
    "    # 95% confidence interval\n",
    "    SE = np.std(payoffs[:,0], ddof=1) / np.sqrt(n_trials)\n",
    "    lower = price-1.96*SE\n",
    "    upper = price+1.96*SE\n",
    "\n",
    "    return price, lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models choice ##\n",
    "\n",
    "In this project, I carefully chose four different machine learning approaches for the regression component within the Longstaff-Schwartz algorithm. For all models, the inputs are the stock prices for in-the-money paths only and the targets are discounted expected values of the option at the next timestep:\n",
    "\n",
    "- **Polynomial Regression**\n",
    "  - **Reason I chose this model:** This is the traditional baseline model that is typically implemented in the LS algorithm. It is computationally efficient, and should perform well in capturing the exercise boundary if it can be described by a polynomial.\n",
    "  - **How it fits in the LS Algorithm:** At every timestep, the model tries to fit a polynomial of degree n for a function to find expected values of the option based on the current stock price. Predictions from this model come from the determined polynomial.\n",
    "  \n",
    "- **Random Forest**\n",
    "  - **Reason I chose this model:** A random forest model could do a better job in this handling potential discontinuities that polynomial regression would not be able to handle. It can capture non-linear exercise boundaries without assuming an overall functional form.\n",
    "  - **How it fits in the LS Algorithm:** At every timestep, the model creates several decision trees to categorize the expected value of the option based on the current stock price. It then averages the results from these trees for the final prediction.\n",
    "\n",
    "- **XGBoost**\n",
    "  - **Reason I chose this model:** This model could potentially be more efficient and robust than random forest. While both are ensemble algorithms, the sequential boosting in XGBoost could capture a lot more details that could be missed from the parallel bagging in random forest. Also, regularization will help model to avoid overfitting.\n",
    "  - **How it fits in the LS Algorithm:** At every timestep, the model uses gradient boosting to sequentially add weak learners, each correcting previous errors to create a final robust learner. This final learner will be able to predict expected values of the option based on the current stock price. \n",
    "\n",
    "- **Multi-Layer Perceptron (MLP)**\n",
    "  - **Reason I chose this model:** This model could theoretically outperform all other models given the correct hyperparameter tuning and regularization. Neural networks work well with large amounts of data, so using it in an algorithm that also uses Monte Carlo Simulation could have promising results.\n",
    "  - **How it fits in the LS Algorithm:** At every timestep, layers of neurons are created, implicitly discovering its own relevant features and finding more nuanced patterns in the data. Then, using backpropagation, the MLP assigns weights to each neuron to create a universal function approximator capable of learning complex stock price to continuation value mappings.\n",
    "\n",
    "For my benchmark, all ML-enhanced Longstaff-Schwartz results are compared against the binomial tree model, a widely accepted lattice-based pricing method that provides reliable American option valuations through backward induction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
